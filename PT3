# OpenCV 와 얼굴 검출

import os
import sys
import numpy as np
import cv2
import matplotlib.pyplot as plt
plt.style.use('seaborn-white')

base_path = r'D:\DevRoot\dataset\ComputerVision\dnnface'

# ↓ Google Colab 에서 
# from google.colab.patches import cv2_imshow  # 이미지를 보여줄 경우 필요
# from google.colab import files # 파일을 업로드 할때 필요

def cv2_imshow(image):
    cv2.imshow('image', image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
def plt_imshow_bgr(bgr_img):
    cvtImg = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)
    plt.imshow(cvtImg)
    plt.show()

#### download_weights.py 

# https://github.com/opencv/opencv/tree/master/samples/dnn/face_detector

# download_weights.py  
# weights.meta4 
# 를 다운로드 합니다 (하나의 폴더에 두고)

from __future__ import print_function
import hashlib
import time
import sys
import xml.etree.ElementTree as ET
if sys.version_info[0] < 3:
    from urllib2 import urlopen
else:
    from urllib.request import urlopen

class HashMismatchException(Exception):
    def __init__(self, expected, actual):
        Exception.__init__(self)
        self.expected = expected
        self.actual = actual
    def __str__(self):
        return 'Hash mismatch: {} vs {}'.format(self.expected, self.actual)

class MetalinkDownloader(object):
    BUFSIZE = 10*1024*1024
    NS = {'ml': 'urn:ietf:params:xml:ns:metalink'}
    tick = 0

    def download(self, metalink_file):
        status = True
        for file_elem in ET.parse(metalink_file).getroot().findall('ml:file', self.NS):
            url = file_elem.find('ml:url', self.NS).text
            fname = file_elem.attrib['name']
            hash_sum = file_elem.find('ml:hash', self.NS).text
            print('*** {}'.format(fname))
            try:
                self.verify(hash_sum, fname)
            except Exception as ex:
                print('  {}'.format(ex))
                try:
                    print('  {}'.format(url))
                    with open(fname, 'wb') as file_stream:
                        self.buffered_read(urlopen(url), file_stream.write)
                    self.verify(hash_sum, fname)
                except Exception as ex:
                    print('  {}'.format(ex))
                    print('  FAILURE')
                    status = False
                    continue
            print('  SUCCESS')
        return status

    def print_progress(self, msg, timeout = 0):
        if time.time() - self.tick > timeout:
            print(msg, end='')
            sys.stdout.flush()
            self.tick = time.time()

    def buffered_read(self, in_stream, processing):
        self.print_progress('  >')
        while True:
            buf = in_stream.read(self.BUFSIZE)
            if not buf:
                break
            processing(buf)
            self.print_progress('>', 5)
        print(' done')

    def verify(self, hash_sum, fname):
        sha = hashlib.sha1()
        with open(fname, 'rb') as file_stream:
            self.buffered_read(file_stream, sha.update)
        if hash_sum != sha.hexdigest():
            raise HashMismatchException(hash_sum, sha.hexdigest())

if __name__ == '__main__':
    sys.exit(0 if MetalinkDownloader().download('weights.meta4') else 1)

# 학습된모델 및 모델설명 파일
model = os.path.join(base_path, 'res10_300x300_ssd_iter_140000_fp16.caffemodel')
config = os.path.join(base_path, 'deploy.prototxt')


# 카메라 오픈
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print('Camera open failed!')
    exit()
else:    
    # 한장 가져오기
    _, frame = cap.read()
    if frame is None:
        print('읽어오기 실패')    

# 어떤 이미지인지 확인해보기
conv_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
plt.imshow(conv_img) 

cap.release()

# 모델 네트워크 읽어오기
net = cv2.dnn.readNet(model, config)

if net.empty():
    print('Net open failed!')
    exit()


# 추론(예측)

blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123))
net.setInput(blob)
detect = net.forward()


print(detect.shape)


# (1, 1, 200, 7)
# (1, 1, N, 7)
# 위에서 뒤의 N x 7 만 필요

detect = detect[0, 0, :, :]
print(detect.shape)  # (200, 7)   <--- 200개의 검출객체

# 그중에서 첫번째것
detect[0]

# array([0.        , 1.        , 
#        0.9976707 ,  # <-- 요게 confidence 값이다 (얼굴일 확률)
#        0.27362424, 0.25893724, 0.49903744, 0.6867151   (얼굴의 사각형 좌표, 정규화된 값)
# ], dtype=float32)

# 입력 프레임의 크기
(h, w) = frame.shape[:2]

h, w

for i in range(detect.shape[0]):
    confidence = detect[i, 2]
    
    if confidence < 0.5:   # 사람 얼굴일 확률 50% 이상만 확인
        break              # confidence 값이 내림차순으로 정렬되어 있다. 0.5 미만이면 더이상 볼필요 없다.
        

    # detect 안의 x1,y1,x2,y2 값은 0.0 ~ 1.0 으로 정규화 되어 있어서 
    # 이를 실제 frame 에 맞추려면 아래와 같이 한다
    x1 = int(detect[i, 3] * w)
    y1 = int(detect[i, 4] * h)
    x2 = int(detect[i, 5] * w)
    y2 = int(detect[i, 6] * h)

    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0))

    label = 'Face: %4.3f' % confidence
    cv2.putText(frame, label, (x1, y1 - 1), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)



# 결과 확인
plt_imshow_bgr(frame)

##### dnnface.py 

import os
import cv2
base_path = r'D:\DevRoot\dataset\ComputerVision\dnnface'

# 학습된모델 및 모델설명 파일
model = os.path.join(base_path, 'res10_300x300_ssd_iter_140000_fp16.caffemodel')
config = os.path.join(base_path, 'deploy.prototxt')
# model = 'res10_300x300_ssd_iter_140000_fp16.caffemodel'
# config = 'deploy.prototxt'
#model = 'opencv_face_detector_uint8.pb'
#config = 'opencv_face_detector.pbtxt'

cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print('Camera open failed!')
    exit()

net = cv2.dnn.readNet(model, config)

if net.empty():
    print('Net open failed!')
    exit()

while True:  # 무한루프 돌면서 가져오기
    _, frame = cap.read()
    if frame is None:
        break

    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123))
    net.setInput(blob)
    detect = net.forward()

    detect = detect[0, 0, :, :]
    (h, w) = frame.shape[:2]

    for i in range(detect.shape[0]):
        confidence = detect[i, 2]
        if confidence < 0.5:
            break

        x1 = int(detect[i, 3] * w)
        y1 = int(detect[i, 4] * h)
        x2 = int(detect[i, 5] * w)
        y2 = int(detect[i, 6] * h)

        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0))

        label = 'Face: %4.3f' % confidence
        cv2.putText(frame, label, (x1, y1 - 1), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)

    cv2.imshow('frame', frame)

    if cv2.waitKey(1) == 27: # ESC 눌려야 빠져 나옴
        break

cap.release()        
cv2.destroyAllWindows()
